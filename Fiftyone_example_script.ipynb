{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7m7P53R7G6t8"
      },
      "outputs": [],
      "source": [
        "!pip install fiftyone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LY6wXVqjHVrZ"
      },
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "import os\n",
        "fo.list_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "T4c9zRs3pC-0"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "# Create the local directory if it doesn't exist\n",
        "mkdir -p /missouri\n",
        "\n",
        "# Download files using gsutil\n",
        "gsutil -m cp -r \"gs://public-datasets-lila/missouricameratraps/images/Set1/1.60-Red_Fox/SEQ75195\" \"/missouri\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "278-_jaUZx7T"
      },
      "outputs": [],
      "source": [
        "name = 'missouri'\n",
        "if fo.dataset_exists(name):\n",
        "  dataset = fo.load_dataset(name)\n",
        "else:\n",
        "  dataset = fo.Dataset.from_images_dir(\"/missouri/\")\n",
        "  dataset.name = name\n",
        "  dataset.compute_metadata()\n",
        "  dataset.save()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWtDEq3yaE5E"
      },
      "outputs": [],
      "source": [
        "fo.list_datasets()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE2IlEPxafqm"
      },
      "outputs": [],
      "source": [
        "fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77p3HDDIfaaT"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import io\n",
        "import urllib\n",
        "import json\n",
        "\n",
        "url = \"https://lila.science/public/lila-md-results/missouri-camera-traps_mdv5a.0.0_results.json.zip\"\n",
        "access_url = urllib.request.urlopen(url)\n",
        "\n",
        "z = zipfile.ZipFile(io.BytesIO(access_url.read()))\n",
        "data = json.loads(z.read(z.infolist()[0]).decode())\n",
        "print(data['detection_categories'])\n",
        "print(data['images'][:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lv5e-H5owj8i"
      },
      "outputs": [],
      "source": [
        "sample_images = os.listdir('/missouri/SEQ75195')\n",
        "keep_data = {os.path.basename(dat['file']): dat['detections'] for dat in data['images'] if any(os.path.basename(samp) in dat['file'] for samp in sample_images)}\n",
        "print(keep_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkcIicaoyYkU"
      },
      "outputs": [],
      "source": [
        "cat_dict = data['detection_categories']\n",
        "for sample in dataset.iter_samples(progress = True, autosave = True):\n",
        "  dat_name = os.path.basename(sample.filepath)\n",
        "  dets = keep_data[dat_name]\n",
        "  add_dets = []\n",
        "  for det in dets:\n",
        "    add_dets.append(fo.Detection(\n",
        "        label = cat_dict[det['category']],\n",
        "        bounding_box = det['bbox'],\n",
        "        confidence = det['conf']\n",
        "    ))\n",
        "  sample['MegaDetector'] = fo.Detections(detections = add_dets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14LbfRJjMmm8"
      },
      "outputs": [],
      "source": [
        "fo.launch_app(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "pVV-4JkQISMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "inpath = '/content/drive/MyDrive/Colab/ground_truth.csv'\n",
        "df = pd.read_csv(inpath)\n",
        "field = 'ground_truth'\n",
        "for sample in dataset.iter_samples(progress = True, autosave = True):\n",
        "        sub = df.loc[df['Filepath'].apply(lambda x: os.path.basename(x)) == os.path.basename(sample.filepath)] # this will only work if every file in your dataset has a unique name!!!\n",
        "        dets = []\n",
        "        for index, row in sub.iterrows():\n",
        "            bbox = [\n",
        "                row['XMin'],\n",
        "                row['YMin'],\n",
        "                row['Width'],\n",
        "                row['Height']\n",
        "            ]\n",
        "            det = fo.Detection(\n",
        "                label = row['Label'],\n",
        "                bounding_box = bbox,\n",
        "                confidence = row['Confidence']\n",
        "            )\n",
        "            dets.append(det)\n",
        "        sample[field] = fo.Detections(detections = dets)"
      ],
      "metadata": {
        "id": "pwdsyxTZJzJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fo.launch_app(dataset)"
      ],
      "metadata": {
        "id": "UmHVLaokJJL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = fo.evaluate_detections(\n",
        "    dataset,\n",
        "    pred_field = 'MegaDetector',\n",
        "    gt_field = 'ground_truth',\n",
        "    classwise = False\n",
        ")\n",
        "results.plot_confusion_matrix()"
      ],
      "metadata": {
        "id": "Kl_y7ff_NWNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from fiftyone import ViewField as VF\n",
        "high_conf_view = dataset.filter_labels('MegaDetector', VF('confidence') > 0.1, only_matches = False)\n",
        "results = fo.evaluate_detections(\n",
        "    high_conf_view,\n",
        "    pred_field = 'MegaDetector',\n",
        "    gt_field = 'ground_truth',\n",
        "    classwise = False\n",
        ")\n",
        "results.plot_confusion_matrix()"
      ],
      "metadata": {
        "id": "9NTFxCV7OKyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4gqzJPIB_IMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code snippet to make a fiftyone dataset directly from MegaDetector outputs\n",
        "# AND output results to a csv\n",
        "!pip install fiftyone\n",
        "import pandas as pd\n",
        "import fiftyone as fo\n",
        "import json\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "with open(\"batch_output.json\", 'r') as f:\n",
        "    batch_output = json.load(f)\n",
        "model_name = \"MegaDet\"\n",
        "encoding_2_class = batch_output[\"categories\"]\n",
        "dataset_name = 'my_favorite_dataset'\n",
        "if fo.dataset_exists(dataset_name):\n",
        "    fo_dataset = fo.load_dataset(dataset_name)\n",
        "else:\n",
        "    fo_dataset = fo.Dataset(dataset_name)\n",
        "results = []\n",
        "for img_output in batch_output[\"annotations\"]:\n",
        "    filepath = img_output[\"img_id\"]\n",
        "    try:\n",
        "        sample = fo_dataset[filepath] #exception if not in dataset\n",
        "    except:\n",
        "        sample = fo.Sample(filepath=filepath)\n",
        "        fo_dataset.add_sample(sample)\n",
        "    img = Image.open(filepath)\n",
        "    img_width, img_height = img.size\n",
        "    fiftyone_detections = []\n",
        "    for i in range(len(img_output[\"bbox\"])):\n",
        "        xmin, ymin, xmax, ymax = img_output[\"bbox\"][i]\n",
        "        x = xmin / img_width\n",
        "        y = ymin / img_height\n",
        "        w = (xmax - xmin) / img_width\n",
        "        h = (ymax - ymin) / img_height\n",
        "        det = fo.Detection(\n",
        "            label=encoding_2_class[str(img_output[\"category\"][i])],\n",
        "            bounding_box=[x, y, w, h],\n",
        "            confidence=img_output[\"confidence\"][i],\n",
        "        )\n",
        "        fiftyone_detections.append(det)\n",
        "        results.append([\n",
        "          img_output['img_id'],\n",
        "          encoding_2_class[str(img_output['category'][i])],\n",
        "          img_output['confidence'][i],\n",
        "          x,\n",
        "          y,\n",
        "          w,\n",
        "          h\n",
        "      ])\n",
        "    sample[model_name] = fo.Detections(detections = fiftyone_detections)\n",
        "    sample.save()\n",
        "dataframe = pd.DataFrame(\n",
        "    results,\n",
        "    columns=[\n",
        "        'image_id',\n",
        "        'category',\n",
        "        'confidence',\n",
        "        'xmin',\n",
        "        'ymin',\n",
        "        'xmax',\n",
        "        'ymax'\n",
        "    ]\n",
        ")\n",
        "print(dataframe)\n",
        "dataframe.to_csv(\"demo_output/batch_output.csv\", index = False)\n",
        "session = fo.launch_app(fo_dataset, remote=False, port=1122)"
      ],
      "metadata": {
        "id": "iQdtUT1B_uEO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}